**1) Describe the null hypotheses to which the p-values given in Table 3.4 correspond. Explan what conclusions you can draw based on these p-values. Your explanaton should be phrased in terms of sales, TV, radio and newspaper. Rather than in terms of the coefficients of the linear model.**

_Table 3.4_:

          | Coefficient | Std. error | t-statistic | p-value
 -------- | ----------- | ---------- | ----------- | -------
Intercept | 2.939       | 0.3119     | 9.42        | < 0.0001
TV        | 0.046       | 0.0014     | 32.81       | < 0.0001
radio     | 0.189       | 0.0086     | 21.89       | < 0.0001
newspaper | -0.001      | 0.0059     | -0.18       | 0.8599

**a)**
Sales p-value corresponds to the null hypothesis that the coefficient for the intercept term is 0. Since the p-value for this hypothesis is below the threshold we may reject the null hypothesis in favor of the alternate hypothesis that the coefficient is non-zero.

**b)**
TV p-value corresponds to the null hypothesis that the coefficient for the TV term is 0. Since the p-value for this hypothesis is below the threshold we may reject the null hypothesis in favor of the alternate hypothesis that the coefficient is non-zero.

**c)**
Radio p-value corresponds to the null hypothesis that the coefficient for the Radio term is 0. Since the p-value for this hypothesis is below the threshold we may reject the null hypothess in favor of the alternate hypothesis that the coefficient is non-zero.

**d)**
Newspaper p-value corresponds to the null hypothesis that the coefficient for the newspaper term is 0. Since the p-value for the hypothesis is above the threshold we may not reject the null hypothesis in favor of the alternate hypothesis that the coefficient is non-zero. Thus we must accept that the newspaper term may be zero.

**2) Carefully explain the difference between KNN Classifier and KNN Regression.**

_KNN Classfier_ and _KNN Regression_ are related. KNN Classifier works by assigning points to a centroid and then recalculating the position of the centroids, this is iterated on until the assignments do not change for the K centroids. The regression works by collecting K points near x in _f(x)_ and averaging their values over each dimension to estimate f hat of x.


**3) Suppose we have a data set with ﬁve predictors, X1 = GPA,X2 = IQ, X3 = Gender (1 for Female and 0 for Male), X4 = Interaction between GPA and IQ, and X5 = Interaction between GPA and Gender. The response is starting salary after graduation (in thousands of dollars). Suppose we use least squares to ﬁt the model, and get ˆ β0 = 50 , ˆ β1 = 20, ˆ β2 =0 .07, ˆ β3 = 35 , ˆ β4 =0 .01, ˆ β5 =−10.
(a) Which answer is correct, and why?
	i. For a ﬁxed value of IQ and GPA, males earn more on average than females.
	ii. For a ﬁxed value of IQ and GPA, females earn more on average than males.
		Since the value for β3 = 35, I think ii) is the right answer. The reason for this is that if X3, the corresponding term is 0 (for males) I think the overall
		value of sum(βi*Xi) for all βi,Xi will be lower since it will be missing that positive 35 term in the sum. That term will be present for females.
	iii. For a ﬁxed value of IQ and GPA, males earn more on average than females provided that the GPA is high enough.
		I think this is more correct now due to the last term which is negative. See calculation below.
	iv. For a ﬁxed value of IQ and GPA, females earn more on average than males provided that the GPA is high enough.
(b) Predict the salary of a female with IQ of 110 and a GPA of 4.0.
	```
	^f([X0=1, X1=4.0, X2=110, X3=1, X4=110*4.0, X5=4.0*1.0]) = βX^t = β0*X0+β1*X1+β2*X2+β3*X3+β4*X4+β5*X5 =
		50 + 20*4.0 + 0.07*110 + 35*1 + 0.01*110*4.0 - 10*4.0*1.0 =
		50 + 80     + 7.7      + 35   + 4.4          - 40 = 130 + 42.7 + 4.4 - 40 = 90 + 47.1 - 40 = 90 + 7.1 = 97.1
	```
	**97.1**
(c) True or false: Since the coeﬃcient for the GPA/IQ interaction term is very small, there is very little evidence of an interaction eﬀect. Justify your answer.
False, we would need to evaluate the p-value before making such a conclusion.
**

**4)a** We would expect the training _RSS_ to be lower for the cubic regression since it will capture the linear trend as well as additional noise in the training data.
**4)b** We would expect the test _RSS_ to be lower for the linear regression since it doesn't account for the noise and more closely matches the source linear trend in the data.
**4)c** We would expect the training _RSS_ to be lower for the cubic regression because it will capture more information about individual data points than the linear regression.
**4)d** There is not enough information for this question.

**5)** See math.png in this folder.
