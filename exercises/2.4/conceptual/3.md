```
We now revisit the bias-variance decomposition.
```
##### (a) Provide a sketch of typical (squared) bias, variance, training er- ror, test error, and Bayes (or irreducible) error curves, on a sin- gle plot, as we go from less flexible statistical learning methods towards more flexible approaches. The x -axis should represent the amount of flexibility in the method, and the y -axis should represent the values for each curve. There should be five curves.  Make sure to label each one.
  - See curves.png
##### (b) Explain why each of the Ô¨Åve curves has the shape displayed in part (a).
  - test error
    - In the least flexible methods their inflexibility will lead to high levels of test errors since they
      are unable to fit the data. They will at first decline in test error rate but as it begins to fit
      the noise in the training set the test error will climb again.
  - train error
    - In the least flexible methods their inflexibility will lead to high levels of training set errors since
      it will be unable to fit the data. However, as it begins to fit even the noise in the training set the
      training error rate will approach zero.
  - Bias^2
    - In the least flexible methods their bias will be large, but as the flexibility increases the data will 
      increasingly affect the output--causing the bias to drop.
  - Variance
    - In the least flexible methods their output will remain constant regardless of the input data. As the method
      becomes more flexible data will increasingly cause the output to vary causing the variance to climb.
  - Irreducible error
    - The irreducible error will remain constant at all times.

